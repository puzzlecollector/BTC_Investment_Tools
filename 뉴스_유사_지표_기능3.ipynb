{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c87dab0b-8c33-46ad-bc91-de4a184b118f",
   "metadata": {},
   "source": [
    "### 기능 3: 뉴스 유사도 기반 패턴 매칭 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc6c9511-d7d4-42a4-afbc-334b30bb3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F  \n",
    "import torch \n",
    "import math \n",
    "import faiss # pip install faiss-cpu \n",
    "from datetime import datetime, timedelta \n",
    "import json \n",
    "from tokenization_roberta_spm import FairSeqRobertaSentencePieceTokenizer\n",
    "from transformers import * \n",
    "import ccxt\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b36f41b0-c8c9-4830-afa4-1724b0a1fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0da4544-39c0-4adf-8659-70534dd95236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109280, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load candidate embeddings \n",
    "candidate_embeddings = np.load(\"candidate_embeddings_full.npy\") \n",
    "\n",
    "candidate_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667453a2-fd50-487f-a9cc-4a8e6e5df6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109280, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load news dataframe \n",
    "news_df = pd.read_csv(\"coinness_full.csv\") \n",
    "\n",
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097bd10a-0787-46ec-b35a-c260bb1eee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>contents</th>\n",
       "      <th>datetimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TUSD/USDT 페어, 오늘 최대 80센트까지 디페깅 심화</td>\n",
       "      <td>코인데스크가 트레이딩뷰 데이터를 인용해 바이낸스US 기준 TUSD/USDT 페어가 ...</td>\n",
       "      <td>2023-06-28 15:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFC, 블록체인 게임 플랫폼 젬허브와 파트너십</td>\n",
       "      <td>바이프로스트(BFC)가 공식 미디엄을 통해 블록체인 게임 플랫폼 젬허브(GemHUB...</td>\n",
       "      <td>2023-06-28 15:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삭제 됐다던 탈중앙화 SNS 다무스, 앱스토어서 v1.5 출시</td>\n",
       "      <td>앱스토어에서 전날 삭제된 것으로 알려진 탈중앙화 소셜 네트워크 프로토콜 노스트(No...</td>\n",
       "      <td>2023-06-28 15:29:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               titles  \\\n",
       "0   TUSD/USDT 페어, 오늘 최대 80센트까지 디페깅 심화   \n",
       "1          BFC, 블록체인 게임 플랫폼 젬허브와 파트너십   \n",
       "2  삭제 됐다던 탈중앙화 SNS 다무스, 앱스토어서 v1.5 출시   \n",
       "\n",
       "                                            contents            datetimes  \n",
       "0  코인데스크가 트레이딩뷰 데이터를 인용해 바이낸스US 기준 TUSD/USDT 페어가 ...  2023-06-28 15:34:00  \n",
       "1  바이프로스트(BFC)가 공식 미디엄을 통해 블록체인 게임 플랫폼 젬허브(GemHUB...  2023-06-28 15:31:00  \n",
       "2  앱스토어에서 전날 삭제된 것으로 알려진 탈중앙화 소셜 네트워크 프로토콜 노스트(No...  2023-06-28 15:29:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d75a12f3-00aa-4d6e-82c7-22df199df47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = news_df[\"titles\"].values \n",
    "contents = news_df[\"contents\"].values \n",
    "published_datetimes = news_df[\"datetimes\"].values \n",
    "\n",
    "candidate_texts = [] \n",
    "for i in range(len(contents)):\n",
    "    s = str(titles[i]) + \"\\n\" + str(contents[i]) \n",
    "    candidate_texts.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e88df6-deca-4660-91d0-753e6b57a582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file fairseq-roberta-all-model/added_tokens.json. We won't load it.\n",
      "Didn't find file fairseq-roberta-all-model/special_tokens_map.json. We won't load it.\n",
      "Didn't find file fairseq-roberta-all-model/tokenizer_config.json. We won't load it.\n",
      "loading file fairseq-roberta-all-model/spm.model\n",
      "loading file fairseq-roberta-all-model/dict.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file fairseq-roberta-all-model/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"fairseq-roberta-all-model\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52001\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'FairSeqRobertaSentencePieceTokenizer'.\n",
      "loading configuration file https://huggingface.co/LDKSolutions/KR-cryptoroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5acbd794ed75d62f6347bda79a2a0adc5451fefc92468deadecb8cac7e4d0be1.36fa43760e5e542e4e396ae3c952a2088b8b9d1fe91d1063514191de83206874\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"LDKSolutions/KR-cryptoroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/LDKSolutions/KR-cryptoroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7cb4817d406f59cf11d9a207e87a8dfc8893a8f3ab75edcb7363d0d065fd31e9.220e7c84f9cf2e8fc1af3dd216ee2ca241d4fb75eff887a69f809a60d35315d3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PASS] spm_id: madeupword0000 | fairseq_id: 51998\n",
      "[PASS] spm_id: madeupword0001 | fairseq_id: 51999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at LDKSolutions/KR-cryptoroberta-base were not used when initializing XLMRobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at LDKSolutions/KR-cryptoroberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/LDKSolutions/KR-cryptoroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5acbd794ed75d62f6347bda79a2a0adc5451fefc92468deadecb8cac7e4d0be1.36fa43760e5e542e4e396ae3c952a2088b8b9d1fe91d1063514191de83206874\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"LDKSolutions/KR-cryptoroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FairSeqRobertaSentencePieceTokenizer.from_pretrained(\"fairseq-roberta-all-model\") \n",
    "embedding_model = AutoModel.from_pretrained(\"LDKSolutions/KR-cryptoroberta-base\")\n",
    "config = AutoConfig.from_pretrained(\"LDKSolutions/KR-cryptoroberta-base\") \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "embedding_model.to(device)\n",
    "embedding_model.eval() \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7be232-8515-4724-a5f6-8ff99fd5fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/LDKSolutions/KR-cryptoroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5acbd794ed75d62f6347bda79a2a0adc5451fefc92468deadecb8cac7e4d0be1.36fa43760e5e542e4e396ae3c952a2088b8b9d1fe91d1063514191de83206874\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"fairseq-roberta-all-model/checkpoint_last.pt\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/LDKSolutions/KR-cryptoroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7cb4817d406f59cf11d9a207e87a8dfc8893a8f3ab75edcb7363d0d065fd31e9.220e7c84f9cf2e8fc1af3dd216ee2ca241d4fb75eff887a69f809a60d35315d3\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at LDKSolutions/KR-cryptoroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = XLMRobertaForSequenceClassification.from_pretrained(\"LDKSolutions/KR-cryptoroberta-base\") \n",
    "sentiment_model.to(device) \n",
    "sentiment_model.eval() \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2814e1-8859-4732-92e0-ffded4471ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate news sentiment score\n",
    "def get_sentiment_score(text): \n",
    "    encoded_inputs = tokenizer(text, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device) \n",
    "    with torch.no_grad(): \n",
    "        sentiment = sentiment_model(**encoded_inputs)[0] \n",
    "        sentiment = nn.Softmax(dim=1)(sentiment)[0] \n",
    "    return sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a6d5d6-44e1-48ed-a4f6-0c8c4936c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 뉴스 문서들의 임베딩을 이용해서 인덱스를 FAISS를 사용해서 빌드한다. \n",
    "# 인덱스를 빌드하는 이유는 빠른 검색을 위해서다. \n",
    "use_cosine_sim = True # using cosine similarity \n",
    "if use_cosine_sim: \n",
    "    index = faiss.IndexIDMap2(faiss.IndexFlatIP(config.hidden_size)) \n",
    "    faiss.normalize_L2(candidate_embeddings.astype(np.float32)) \n",
    "else: # defaults to L2 \n",
    "    index = faiss.IndexIDMap2(faiss.IndexFlatL2(config.hidden_size)) \n",
    "\n",
    "index.add_with_ids(candidate_embeddings.astype(np.float32), np.array(range(0, len(candidate_embeddings)), dtype=int)) \n",
    "index.nprobe = 64 # hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee4e4086-0c0f-4017-81ae-052458b5b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_chart_data_to_pd(json_file:str):\n",
    "    with open(json_file) as f: \n",
    "        d = json.load(f) \n",
    "    chart_df = pd.DataFrame(d) \n",
    "    chart_df = chart_df.rename(columns={0:\"timestamp\", 1:\"open\", 2:\"high\", 3:\"low\", 4:\"close\", 5:\"volume\"})\n",
    "    binance = ccxt.binance() \n",
    "    dates = chart_df[\"timestamp\"].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)): \n",
    "        date_string = binance.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5]\n",
    "        timestamp.append(date_string) \n",
    "    chart_df[\"datetime\"] = timestamp \n",
    "    chart_df.drop(columns={\"timestamp\"}, inplace=True) \n",
    "    chart_df.set_index(pd.DatetimeIndex(chart_df[\"datetime\"]), inplace=True) \n",
    "    return chart_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b518181-c980-428e-81ad-dd47bb28734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 30m BTCUSDT chart data \n",
    "df30m = convert_json_chart_data_to_pd(\"btcusdt_binance_30m_20230829.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e45c0171-bc10-4a41-a1a8-14e668ee49a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17 04:00:00</th>\n",
       "      <td>4261.48</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4261.45</td>\n",
       "      <td>11.308926</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 04:30:00</th>\n",
       "      <td>4280.00</td>\n",
       "      <td>4313.62</td>\n",
       "      <td>4267.99</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>35.872083</td>\n",
       "      <td>2017-08-17 04:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 05:00:00</th>\n",
       "      <td>4308.83</td>\n",
       "      <td>4328.69</td>\n",
       "      <td>4304.31</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>21.048648</td>\n",
       "      <td>2017-08-17 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 05:30:00</th>\n",
       "      <td>4320.00</td>\n",
       "      <td>4320.00</td>\n",
       "      <td>4291.37</td>\n",
       "      <td>4315.32</td>\n",
       "      <td>2.186268</td>\n",
       "      <td>2017-08-17 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 06:00:00</th>\n",
       "      <td>4330.29</td>\n",
       "      <td>4330.29</td>\n",
       "      <td>4309.37</td>\n",
       "      <td>4311.02</td>\n",
       "      <td>3.566277</td>\n",
       "      <td>2017-08-17 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29 10:00:00</th>\n",
       "      <td>25992.23</td>\n",
       "      <td>25992.23</td>\n",
       "      <td>25953.13</td>\n",
       "      <td>25962.02</td>\n",
       "      <td>446.816260</td>\n",
       "      <td>2023-08-29 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29 10:30:00</th>\n",
       "      <td>25962.01</td>\n",
       "      <td>25991.40</td>\n",
       "      <td>25922.00</td>\n",
       "      <td>25981.27</td>\n",
       "      <td>478.771960</td>\n",
       "      <td>2023-08-29 10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29 11:00:00</th>\n",
       "      <td>25981.27</td>\n",
       "      <td>26046.00</td>\n",
       "      <td>25978.03</td>\n",
       "      <td>26007.14</td>\n",
       "      <td>545.877740</td>\n",
       "      <td>2023-08-29 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29 11:30:00</th>\n",
       "      <td>26007.14</td>\n",
       "      <td>26011.01</td>\n",
       "      <td>25961.97</td>\n",
       "      <td>25975.55</td>\n",
       "      <td>348.596280</td>\n",
       "      <td>2023-08-29 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29 12:00:00</th>\n",
       "      <td>25975.54</td>\n",
       "      <td>25994.23</td>\n",
       "      <td>25964.79</td>\n",
       "      <td>25988.89</td>\n",
       "      <td>243.375600</td>\n",
       "      <td>2023-08-29 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105486 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close      volume  \\\n",
       "datetime                                                                  \n",
       "2017-08-17 04:00:00   4261.48   4280.56   4261.32   4261.45   11.308926   \n",
       "2017-08-17 04:30:00   4280.00   4313.62   4267.99   4308.83   35.872083   \n",
       "2017-08-17 05:00:00   4308.83   4328.69   4304.31   4320.00   21.048648   \n",
       "2017-08-17 05:30:00   4320.00   4320.00   4291.37   4315.32    2.186268   \n",
       "2017-08-17 06:00:00   4330.29   4330.29   4309.37   4311.02    3.566277   \n",
       "...                       ...       ...       ...       ...         ...   \n",
       "2023-08-29 10:00:00  25992.23  25992.23  25953.13  25962.02  446.816260   \n",
       "2023-08-29 10:30:00  25962.01  25991.40  25922.00  25981.27  478.771960   \n",
       "2023-08-29 11:00:00  25981.27  26046.00  25978.03  26007.14  545.877740   \n",
       "2023-08-29 11:30:00  26007.14  26011.01  25961.97  25975.55  348.596280   \n",
       "2023-08-29 12:00:00  25975.54  25994.23  25964.79  25988.89  243.375600   \n",
       "\n",
       "                                datetime  \n",
       "datetime                                  \n",
       "2017-08-17 04:00:00  2017-08-17 04:00:00  \n",
       "2017-08-17 04:30:00  2017-08-17 04:30:00  \n",
       "2017-08-17 05:00:00  2017-08-17 05:00:00  \n",
       "2017-08-17 05:30:00  2017-08-17 05:30:00  \n",
       "2017-08-17 06:00:00  2017-08-17 06:00:00  \n",
       "...                                  ...  \n",
       "2023-08-29 10:00:00  2023-08-29 10:00:00  \n",
       "2023-08-29 10:30:00  2023-08-29 10:30:00  \n",
       "2023-08-29 11:00:00  2023-08-29 11:00:00  \n",
       "2023-08-29 11:30:00  2023-08-29 11:30:00  \n",
       "2023-08-29 12:00:00  2023-08-29 12:00:00  \n",
       "\n",
       "[105486 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have data from 2017 august to 2023 august \n",
    "df30m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84d4407a-fd1a-4dda-99f2-f7aa37289618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색이 최적화 되지 않아서 느리긴 하지만 지금 단계에서는 상관 없을듯 \n",
    "def get_relevant_chart_segment(chart_df, datestr): \n",
    "    df30m_idx = -1 \n",
    "    cur_date = chart_df[\"datetime\"].values \n",
    "    news_datestr = datetime.strptime(datestr, \"%Y-%m-%d %H:%M:%S\") \n",
    "    for i in range(len(cur_date)-1): \n",
    "        current_date = datetime.strptime(cur_date[i], \"%Y-%m-%d %H:%M:%S\") \n",
    "        next_date = datetime.strptime(cur_date[i+1], \"%Y-%m-%d %H:%M:%S\") \n",
    "        if news_datestr >= current_date and news_datestr < next_date:\n",
    "            df30m_idx = i \n",
    "            break \n",
    "    return df30m_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5728590-ec31-4e37-ab26-f56fa73c2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query news\n",
      "FT \"온타리오 연기금, 암호화폐 투자 중단...FTX 사태 손실 여파\"\n",
      "파이낸셜타임즈가 FTX 파산 사태로 9500만 달러 상당의 손실을 입은 온타리오 교사연금(OTPP)이 손실 전액을 상각 처리한 뒤 암호화폐 투자에서 손을 떼기로 했다고 보도했다. OTPP 이사장 조 테일러(Jo Taylor)는 \"우리는 FTX 사태로 인한 피해 등에 대해 여전히 내부 조사를 진행하고 있다. 또 연금 가입자들의 피드백을 고려했을 때, 다시 암호화폐 투자에 나서는 것은 현명한 처사가 아니라고 생각한다. 아울러 FTX 사태 이전에 우리는 매우 신중히 실사를 진행한 끝에 투자를 단행했지만 기대했던 결과를 얻지 못했다\"고 설명했다.\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 10% | 중립: 90% ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rank 1\n",
      "\n",
      "포브스 \"FTX 회계 감사 업체 아르마니노, 암호화폐 준비금 감사 서비스 종료\"\n",
      "포브스에 따르면 FTX 회계 감사 업체 아르마니노(Armanino)가 암호화폐 업체에 대한 준비금 증명 감사 서비스를 종료하기로 결정한 것으로 알려졌다. 업계 관계자는 포브스에 \"회사 평판 리스크가 커지면서, 아르마니노가 이 같은 결정을 내렸다. 아직 명확한 회계 기준이 없는 암호화폐 업계 고객을 받아들이는 것을 주저하게 됐다\"고 설명했다. 아르마니노는 지난 2014년부터 암호화폐 업체 회계 감사 서비스를 시작했으며, 이후 FTX를 포함 넥소, 크라켄, 게이트 아이오 등의 준비금 증명 감사를 맡아왔다. 그러나 최근 FTX의 파산 후 집단 소송에 직면하는 등 어려움을 겪고 있다.\n",
      "날짜: 2022-12-16 02:03:00\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 13% | 중립: 86% ***\n",
      "1시간 후 변동성:-0.0542% | 4시간 후 변동성:-0.1364% | 8시간 후 변동성:-2.463% | 12시간 후 변동성:-2.1475% | 24시간 후 변동성:-4.6877%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Rank 2\n",
      "\n",
      "서클, 페이 서비스 지원 전면 중단\n",
      "골드만삭스가 지원하는 암호화폐 기업 서클이 자사의 암호화폐 기반 소셜 결제 서비스인 서클 페이에 대한 지원을 전면 중단한다고 밝혔다. 서클 페이는 현재 미국, 영국 등 29개 국가에서 서비스되고 있다. 암호화폐 미디어 파이낸스 마그네이츠는 이와 관련해 \"서클이 규제 불확실성으로 인해 서비스 방향을 대대적으로 전환하고 있다\"며 \"최근 직원의 10%인 30명을 감원했다\"고 설명했다. 서클 페이는 오는 7월 8일부터 점진적으로 서비스 지원을 중단, 9월 30일 서비스 지원이 완전히 끝난다.\n",
      "날짜: 2019-06-14 04:31:00\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 12% | 중립: 88% ***\n",
      "1시간 후 변동성:-0.2769% | 4시간 후 변동성:+0.5017% | 8시간 후 변동성:+1.4797% | 12시간 후 변동성:+1.1926% | 24시간 후 변동성:+4.4711%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Rank 3\n",
      "\n",
      "모질라 재단, 커뮤니티 반발에 '암호화폐 후원금 허용' 결정 철회\n",
      "블룸버그 통신에 따르면, 4대 주요 웹브라우저 중 하나인 파이어폭스(Firefox) 개발사 모질라 코퍼레이션(Mozilla Corporation)을 감독하는 비영리 조직 모질라 재단이 7일 공식 트위터를 통해 \"암호화폐 결제 프로세서 비트페이를 통한 암호화폐 후원금 수령을 일시 중단한다\"고 밝혔다. 이와 관련 모질라 재단 측은 \"탈중앙화 웹 기술은 연구 가치가 있는 중요 분야지만, 우리가 암호화폐로 후원을 받기 시작한 이후 많은 것이 바뀌었다. 재단은 암호화폐 후원금 관련 기존 정책이 친환경 기후 목표와 부합하는지 재검토하고 있으며, 해당 기간 암호화폐 후원금은 받지 않을 예정이다. 정책 검토는 투명하게 진행될 것이고, 우리는 오픈소스 정신에 따라 정기적인 업데이트를 커뮤니티에 공유할 것\"이라고 설명했다. 앞서 모질라 재단은 지난 1일(현지 시간) 공식 트위터를 통해 DOGE 등을 포함한 암호화폐 후원금을 받기 시작했다고 밝힌 바 있으며, 이에 '암호화폐는 환경 파괴의 주범'을 주장하는 제이미 자윈스키 모질라 공동 창업자를 필두로 커뮤니티의 반발이 일어난 바 있다.\n",
      "날짜: 2022-01-07 08:55:00\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 13% | 중립: 87% ***\n",
      "1시간 후 변동성:+0.7934% | 4시간 후 변동성:+0.7398% | 8시간 후 변동성:+0.1108% | 12시간 후 변동성:-0.3954% | 24시간 후 변동성:-0.294%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Rank 4\n",
      "\n",
      "크립토피아 파산...청산 절차 돌입\n",
      "글로벌 유명 미디어 스터프(stuff)에 따르면 뉴질랜드 암호화폐 거래소 크립토피아가 오늘(15일) 청산 소식을 알리며 암호화폐 거래 서비스를 중단한다고 공지했다. 크립토피아의 파산관재인인 세계 5대 글로벌 회계법인 GT(Grant Thornton)는 \"지난 1월 막대한 영업 손실을 초래한 해킹 사건이 파산으로 이어졌다\"고 설명했다. 이와 관련 크립토피아는 \"운영 지출을 줄이고 이익 창출에 힘썼지만, 결국 청산을 결정했다\"며 \"고객, 임직원, 주주 등 이해당사자들에 최대한 영향이 없도록 최선을 다하겠다\"고 밝혔다. 앞서 암호화폐 커뮤니티에서는 크립토피아의 거래 서비스가 48시간 이상 중단됐다며 또 다시 해킹을 당했거나 앞서 1월 발생한 해킹으로 '야반도주'를 하려는 것 아니냐는 의혹을 제기한 바 있다.\n",
      "날짜: 2019-05-15 13:48:00\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 13% | 중립: 86% ***\n",
      "1시간 후 변동성:-0.6545% | 4시간 후 변동성:+1.486% | 8시간 후 변동성:+2.0805% | 12시간 후 변동성:+4.0753% | 24시간 후 변동성:-1.4047%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Rank 5\n",
      "\n",
      "심플코인, 내년 영업 종료... ”EU KYC/AML 규정 때문”\n",
      "암호화폐 미디어 AMB크립토에 따르면, 네덜란드 암호화폐 채굴 플랫폼 심플코인(Simplecoin)이 오는 2020년 1월 1일 서비스를 종료한다고 발표했다. 심플코인은 “이용자는 오는 20일까지 모든 자금을 출금해야 한다”고 공지했다. 이를 두고 미디어는 “최근 유럽연합(EU)이 시행한 신규 KYC/AML 규정 때문”이라며 “심플코인이 컴플라이언스 압박으로 서비스를 중단한 것으로 보인다”고 분석했다. 유럽연합(EU)은 5차 자금세탁방지 지침(AMLD5)을 제정, 내년 1월부터 시행한다. EU 회원국들은 내년 1월 20일까지 AMLD5 지침을 따라야 한다. AMLD5는 감시 범위를 암호화폐 거래소와 월렛 제공업체까지 확대하고, 거래소나 선불카드를 통해 이뤄지는 익명 거래에 보다 엄격한 투명성을 요구한다.\n",
      "날짜: 2019-12-16 11:29:00\n",
      "*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: 1% | 악재: 22% | 중립: 78% ***\n",
      "1시간 후 변동성:+0.2939% | 4시간 후 변동성:+0.3204% | 8시간 후 변동성:-2.2808% | 12시간 후 변동성:-2.4041% | 24시간 후 변동성:-2.6313%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "GPT-4가 결과 분석중...기다려주세요...\n"
     ]
    }
   ],
   "source": [
    "# example run 1 \n",
    "# 유저가 쿼리 뉴스를 입력했다고 가정 \n",
    "query_title = \"\"\"FT \\\"온타리오 연기금, 암호화폐 투자 중단...FTX 사태 손실 여파\\\"\"\"\" \n",
    "query_content = \"\"\"파이낸셜타임즈가 FTX 파산 사태로 9500만 달러 상당의 손실을 입은 온타리오 교사연금(OTPP)이 손실 전액을 상각 처리한 뒤 암호화폐 투자에서 손을 떼기로 했다고 보도했다. OTPP 이사장 조 테일러(Jo Taylor)는 \"우리는 FTX 사태로 인한 피해 등에 대해 여전히 내부 조사를 진행하고 있다. 또 연금 가입자들의 피드백을 고려했을 때, 다시 암호화폐 투자에 나서는 것은 현명한 처사가 아니라고 생각한다. 아울러 FTX 사태 이전에 우리는 매우 신중히 실사를 진행한 끝에 투자를 단행했지만 기대했던 결과를 얻지 못했다\"고 설명했다.\"\"\"\n",
    "\n",
    "encoded_query = tokenizer(str(query_title), str(query_content), max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "query_embedding = embedding_model(**encoded_query)[0][:, 0, :].detach().cpu().numpy() \n",
    "\n",
    "distances, indices = index.search(query_embedding, 1000) \n",
    "topK = 5 # MVP로는 탑 5개만 보여줌  \n",
    "\n",
    "print(\"query news\")\n",
    "query_text = query_title + \"\\n\" + query_content \n",
    "print(query_text) \n",
    "sentiment_scores = get_sentiment_score(query_text) \n",
    "sentiment_scores = sentiment_scores.detach().cpu().numpy()\n",
    "positive = round(sentiment_scores[0] * 100)  \n",
    "negative = round(sentiment_scores[1] * 100) \n",
    "neutral = round(sentiment_scores[2] * 100) \n",
    "print(f\"*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: {positive}% | 악재: {negative}% | 중립: {neutral}% ***\") \n",
    "\n",
    "for _ in range(5): # 공백 출력 \n",
    "    print() \n",
    "    \n",
    "top5_news, top5_12hr_volatilities = [], [] \n",
    "\n",
    "cnt = 0 \n",
    "for i in range(len(indices[0][:topK+3])): \n",
    "    if candidate_texts[indices[0][i]] == query_text:\n",
    "        continue\n",
    "    if cnt == topK: \n",
    "        break \n",
    "    print(f\"Rank {cnt+1}\") \n",
    "    print() \n",
    "    print(candidate_texts[indices[0][i]])  \n",
    "    top5_news.append(candidate_texts[indices[0][i]]) \n",
    "    print(f\"날짜: {published_datetimes[indices[0][i]]}\") \n",
    "    sentiment_scores = get_sentiment_score(candidate_texts[indices[0][i]]) \n",
    "    sentiment_scores = sentiment_scores.detach().cpu().numpy() \n",
    "    positive = round(sentiment_scores[0] * 100)  \n",
    "    negative = round(sentiment_scores[1] * 100) \n",
    "    neutral = round(sentiment_scores[2] * 100) \n",
    "    print(f\"*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: {positive}% | 악재: {negative}% | 중립: {neutral}% ***\")\n",
    "    cnt += 1 \n",
    "    \n",
    "    # calculate 1hr, 4hrs, 8hrs, 12hrs, 24hrs volatility \n",
    "    news_idx = get_relevant_chart_segment(df30m, published_datetimes[indices[0][i]]) \n",
    "\n",
    "    if news_idx != -1: \n",
    "        #plot_chart(\"BTCUSDT (Binance) 30m\", df30.iloc[news_idx:news_idx+observation_length]) \n",
    "        close = df30m[\"close\"].values[news_idx] \n",
    "        close_1h = df30m[\"close\"].values[news_idx+2] \n",
    "        close_4h = df30m[\"close\"].values[news_idx+8] \n",
    "        close_8h = df30m[\"close\"].values[news_idx+16] \n",
    "        close_12h = df30m[\"close\"].values[news_idx+24] \n",
    "        close_24h = df30m[\"close\"].values[news_idx+48] \n",
    "        delta_1h = round((close_1h - close)/close * 100, 4) \n",
    "        if delta_1h >= 0:\n",
    "            delta_1h = str(delta_1h) \n",
    "            delta_1h = \"+\" + delta_1h\n",
    "        delta_4h = round((close_4h - close)/close * 100, 4)\n",
    "        if delta_4h >= 0:\n",
    "            delta_4h = str(delta_4h) \n",
    "            delta_4h = \"+\" + delta_4h\n",
    "        delta_8h = round((close_8h - close)/close * 100, 4) \n",
    "        if delta_8h >= 0:\n",
    "            delta_8h = str(delta_8h) \n",
    "            delta_8h = \"+\" + delta_8h \n",
    "        delta_12h = round((close_12h - close)/close * 100, 4) \n",
    "        if delta_12h >= 0:\n",
    "            delta_12h = str(delta_12h) \n",
    "            delta_12h = \"+\" + delta_12h \n",
    "        delta_24h = round((close_24h - close)/close * 100, 4) \n",
    "        if delta_24h >= 0:\n",
    "            delta_24h = str(delta_24h) \n",
    "            delta_24h = \"+\" + delta_24h\n",
    "        print(f\"1시간 후 변동성:{delta_1h}% | 4시간 후 변동성:{delta_4h}% | 8시간 후 변동성:{delta_8h}% | 12시간 후 변동성:{delta_12h}% | 24시간 후 변동성:{delta_24h}%\")\n",
    "        top5_12hr_volatilities.append(delta_12h) \n",
    "    else:\n",
    "        print(\"해당 뉴스가 나온 시점의 차트 데이터가 존재하지 않습니다! 다른 차트 데이터 소스를 참고해보세요.\") \n",
    "\n",
    "    print(\"=\" * 100) \n",
    "    print()\n",
    "    print() \n",
    "    \n",
    "top5_news = top5_news[:5] \n",
    "top5_12hr_volatilities = top5_12hr_volatilities[:5]\n",
    "\n",
    "print(\"GPT-4가 결과 분석중...기다려주세요...\") \n",
    "    \n",
    "query = f\"쿼리 뉴스와, 해당 쿼리 뉴스와 유사하다는 과거 뉴스 5개가 유사도 순서로 랭킹이 되었어. 이때 쿼리 뉴스와 랭크된 뉴스 사이에 어떤점들이 유사한지 알기 쉽게 설명해줘. 그리고 쿼리와 유사한 뉴스들이 나온 시점부터 12시간 이후의 가격 변동 정보가 주어졌을때 이 가격 변동간에 상관관계가 있는지 분석해줘. \\n query:{query_text} \\n rank1:{top5_news[0]} \\n 12시간후 가격변동:{top5_12hr_volatilities[0]}% \\n rank2:{top5_news[1]} \\n 12시간후 가격변동:{top5_12hr_volatilities[1]}% \\n rank3:{top5_news[2]} \\n 12시간후 가격변동:{top5_12hr_volatilities[2]}% \\n rank4:{top5_news[3]} \\n 12시간후 가격변동:{top5_12hr_volatilities[3]}% \\n rank5:{top5_news[4]} \\n 12시간후 가격변동:{top5_12hr_volatilities[4]}%\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-4\", \n",
    "    messages = [\n",
    "        {\"role\":\"user\", \"content\":query}\n",
    "    ], \n",
    "    temperature=0.5 \n",
    ")\n",
    "\n",
    "gpt_response = response[\"choices\"][0][\"message\"][\"content\"] \n",
    "\n",
    "print(\"*** GPT-4가 쿼리 뉴스와 가장 유사한 상위 5개의 뉴스와 12시간 가격 변동 데이터를 분석한 결과 ***\")\n",
    "print()\n",
    "print(gpt_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865f905-2b02-4c0d-9ce0-a08b54a4f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example run 2 \n",
    "# 유저가 쿼리 뉴스를 입력했다고 가정 \n",
    "query_title = \"BTC 3년 이상 보유 장기 홀더 비중 40%... 사상 최고\" \n",
    "query_content = \"\"\"코인데스크에 따르면 비트파이넥스 애널리스트들은 3년 이상 BTC를 이동시키지 않은 장기 홀더 비중이 40%로 사상 최고에 달했다고 밝혔다. 이들은 장기 홀더 순포지션 변화를 자세히 보면 오래 3월 이후 일관된 매집 추세를 보였다. 그러나 강세장, 약세장 모두를 견뎌낸 홀더들과는 달리 이번 약세장에서 코인을 매수한 신규 장기 홀더들은 불안감을 내비치고 있다. 이들은 7월 BTC가 $29,000선에서 하락하는 동안 매도에 나섰다고 설명했다.\"\"\"\n",
    "\n",
    "encoded_query = tokenizer(str(query_title), str(query_content), max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "query_embedding = embedding_model(**encoded_query)[0][:, 0, :].detach().cpu().numpy() \n",
    "\n",
    "distances, indices = index.search(query_embedding, 1000) \n",
    "topK = 5 # MVP로는 탑 5개만 보여줌  \n",
    "\n",
    "print(\"query news\")\n",
    "query_text = query_title + \"\\n\" + query_content \n",
    "print(query_text) \n",
    "sentiment_scores = get_sentiment_score(query_text) \n",
    "sentiment_scores = sentiment_scores.detach().cpu().numpy()\n",
    "positive = round(sentiment_scores[0] * 100)  \n",
    "negative = round(sentiment_scores[1] * 100) \n",
    "neutral = round(sentiment_scores[2] * 100) \n",
    "print(f\"*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: {positive}% | 악재: {negative}% | 중립: {neutral}% ***\") \n",
    "\n",
    "for _ in range(5): # 공백 출력 \n",
    "    print() \n",
    "    \n",
    "top5_news, top5_12hr_volatilities = [], [] \n",
    "\n",
    "cnt = 0 \n",
    "for i in range(len(indices[0][:topK+3])): \n",
    "    if candidate_texts[indices[0][i]] == query_text:\n",
    "        continue\n",
    "    if cnt == topK: \n",
    "        break \n",
    "    print(f\"Rank {cnt+1}\") \n",
    "    print() \n",
    "    print(candidate_texts[indices[0][i]])  \n",
    "    top5_news.append(candidate_texts[indices[0][i]]) \n",
    "    print(f\"날짜: {published_datetimes[indices[0][i]]}\") \n",
    "    sentiment_scores = get_sentiment_score(candidate_texts[indices[0][i]]) \n",
    "    sentiment_scores = sentiment_scores.detach().cpu().numpy() \n",
    "    positive = round(sentiment_scores[0] * 100)  \n",
    "    negative = round(sentiment_scores[1] * 100) \n",
    "    neutral = round(sentiment_scores[2] * 100) \n",
    "    print(f\"*** 인공지능이 분석한 비트코인 가격에 대한 영향: 호재: {positive}% | 악재: {negative}% | 중립: {neutral}% ***\")\n",
    "    cnt += 1 \n",
    "    \n",
    "    # calculate 1hr, 4hrs, 8hrs, 12hrs, 24hrs volatility \n",
    "    news_idx = get_relevant_chart_segment(df30m, published_datetimes[indices[0][i]]) \n",
    "\n",
    "    if news_idx != -1: \n",
    "        #plot_chart(\"BTCUSDT (Binance) 30m\", df30.iloc[news_idx:news_idx+observation_length]) \n",
    "        close = df30m[\"close\"].values[news_idx] \n",
    "        close_1h = df30m[\"close\"].values[news_idx+2] \n",
    "        close_4h = df30m[\"close\"].values[news_idx+8] \n",
    "        close_8h = df30m[\"close\"].values[news_idx+16] \n",
    "        close_12h = df30m[\"close\"].values[news_idx+24] \n",
    "        close_24h = df30m[\"close\"].values[news_idx+48] \n",
    "        delta_1h = round((close_1h - close)/close * 100, 4) \n",
    "        if delta_1h >= 0:\n",
    "            delta_1h = str(delta_1h) \n",
    "            delta_1h = \"+\" + delta_1h\n",
    "        delta_4h = round((close_4h - close)/close * 100, 4)\n",
    "        if delta_4h >= 0:\n",
    "            delta_4h = str(delta_4h) \n",
    "            delta_4h = \"+\" + delta_4h\n",
    "        delta_8h = round((close_8h - close)/close * 100, 4) \n",
    "        if delta_8h >= 0:\n",
    "            delta_8h = str(delta_8h) \n",
    "            delta_8h = \"+\" + delta_8h \n",
    "        delta_12h = round((close_12h - close)/close * 100, 4) \n",
    "        if delta_12h >= 0:\n",
    "            delta_12h = str(delta_12h) \n",
    "            delta_12h = \"+\" + delta_12h \n",
    "        delta_24h = round((close_24h - close)/close * 100, 4) \n",
    "        if delta_24h >= 0:\n",
    "            delta_24h = str(delta_24h) \n",
    "            delta_24h = \"+\" + delta_24h\n",
    "        print(f\"1시간 후 변동성:{delta_1h}% | 4시간 후 변동성:{delta_4h}% | 8시간 후 변동성:{delta_8h}% | 12시간 후 변동성:{delta_12h}% | 24시간 후 변동성:{delta_24h}%\")\n",
    "        top5_12hr_volatilities.append(delta_12h) \n",
    "    else:\n",
    "        print(\"해당 뉴스가 나온 시점의 차트 데이터가 존재하지 않습니다! 다른 차트 데이터 소스를 참고해보세요.\") \n",
    "\n",
    "    print(\"=\" * 100) \n",
    "    print()\n",
    "    print() \n",
    "    \n",
    "top5_news = top5_news[:5] \n",
    "top5_12hr_volatilities = top5_12hr_volatilities[:5]\n",
    "\n",
    "print(\"GPT-4가 결과 분석중...기다려주세요...\") \n",
    "    \n",
    "query = f\"쿼리 뉴스와, 해당 쿼리 뉴스와 유사하다는 과거 뉴스 5개가 유사도 순서로 랭킹이 되었어. 이때 쿼리 뉴스와 랭크된 뉴스 사이에 어떤점들이 유사한지 알기 쉽게 설명해줘. 그리고 쿼리와 유사한 뉴스들이 나온 시점부터 12시간 이후의 가격 변동 정보가 주어졌을때 이 가격 변동간에 상관관계가 있는지 분석해줘. \\n query:{query_text} \\n rank1:{top5_news[0]} \\n 12시간후 가격변동:{top5_12hr_volatilities[0]}% \\n rank2:{top5_news[1]} \\n 12시간후 가격변동:{top5_12hr_volatilities[1]}% \\n rank3:{top5_news[2]} \\n 12시간후 가격변동:{top5_12hr_volatilities[2]}% \\n rank4:{top5_news[3]} \\n 12시간후 가격변동:{top5_12hr_volatilities[3]}% \\n rank5:{top5_news[4]} \\n 12시간후 가격변동:{top5_12hr_volatilities[4]}%\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-4\", \n",
    "    messages = [\n",
    "        {\"role\":\"user\", \"content\":query}\n",
    "    ], \n",
    "    temperature=0.5 \n",
    ")\n",
    "\n",
    "gpt_response = response[\"choices\"][0][\"message\"][\"content\"] \n",
    "\n",
    "print(\"*** GPT-4가 쿼리 뉴스와 가장 유사한 상위 5개의 뉴스만 골라서 분석한 결과 ***\")\n",
    "print()\n",
    "print(gpt_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052c923-5d54-446d-bac1-6cab269bb685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70ff8e-265c-4eeb-80ec-c398da503874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd50a06-d14d-4354-accc-d3e0748bfa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80592922-2343-4ba2-9c5f-03804ad2ec3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a6f81-7034-40a7-9fbb-29c0885f0216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
